{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zalcandil/authentic-connections/blob/master/Ebook_Embeddings_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t504qmTJ4RGb"
      },
      "source": [
        "Notes on usage:\n",
        "\n",
        "- Upload an epub file representing the ebook you want to search (tip: ever heard of [libgen](https://libgen.is/)?).\n",
        "- Re-run the last cell using different queries to keep searching the same book. \n",
        "  - The cost of embedding the query is trivial compared to the cost of embedding the whole book, so this is the cheap part.\n",
        "  - Query search results are also appended to 'results.txt' in Files.\n",
        "- You'll need an OpenAI API key to run this notebook, which you can get [here](https://beta.openai.com/account/api-keys) (signing up for an OpenAI account gives you \\$18 of credits). \n",
        "- Choose a model based on price/performance considerations (more info on [pricing](https://openai.com/api/pricing/)). \n",
        "  - Heads up: transcribing long books, or using the bigger models (Curie and Davince) can get really expensive.\n",
        "  - Make sure to set Usage Limits for your OpenAI account.\n",
        "- Embeddings for the book you upload will be saved in Files (in the left menu bar) under the title 'embeddings-{first chapter}-{last chapter}-{model name}-{epub filename}.json'. \n",
        "  - Download this file and upload it (instead of an epub) on your next runtime session in order to avoid calling the OpenAI API again.\n",
        "- Run 'process_file' with 'preview_mode' set to True at first to check which range of chapters you want to index. This helps you avoid needlessly creating embeddings for chapters like 'Notes' and 'Works Cited\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adTvAEfsfR_9",
        "outputId": "0aa039b3-fe55-4d39-f74a-21d9789930fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████▍                        | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 20 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 30 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 40 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 44 kB 2.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 111 kB 46.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 163 kB 37.8 MB/s \n",
            "\u001b[?25h  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ebooklib (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q openai ebooklib\n",
        "import openai\n",
        "import json\n",
        "import ebooklib\n",
        "from ebooklib import epub\n",
        "from bs4 import BeautifulSoup\n",
        "from os.path import exists\n",
        "from IPython.display import HTML, display\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97k5qPqnhAXs"
      },
      "outputs": [],
      "source": [
        "# upload epub (or json of book embeddings generated by this program)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "path = next(iter(uploaded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-25dTTRavt6n"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"sk-\" #@param {type:\"string\"}\n",
        "model = 'babbage' #@param ['ada', 'babbage', 'curie', 'davinci']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNquydT-3Ddc"
      },
      "outputs": [],
      "source": [
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "jBhy3RYSfR__",
        "outputId": "370eb8ac-14b7-4692-c47c-a8f57e6bd1ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def part_to_chapter(part):\n",
        "    soup = BeautifulSoup(part.get_body_content(), 'html.parser')\n",
        "    paragraphs = [para.get_text().strip() for para in soup.find_all('p')]\n",
        "    paragraphs = [para for para in paragraphs if len(para) > 0]\n",
        "    if len(paragraphs) == 0:\n",
        "        return None\n",
        "    title = ' '.join([heading.get_text() for heading in soup.find_all('h1')])\n",
        "    return {'title': title, 'paras': paragraphs}\n",
        "\n",
        "min_words_per_para = 150\n",
        "max_words_per_para = 500\n",
        "\n",
        "def format_paras(chapters):\n",
        "    for i in range(len(chapters)):\n",
        "        for j in range(len(chapters[i]['paras'])):\n",
        "            k = j\n",
        "            while len(chapters[i]['paras'][j].split()) < min_words_per_para and k < len(chapters[i]['paras']) - 1:\n",
        "                chapters[i]['paras'][j] += '\\n' + chapters[i]['paras'][k + 1]\n",
        "                chapters[i]['paras'][k + 1] = ''\n",
        "                k += 1\n",
        "            split_para = chapters[i]['paras'][j].split()\n",
        "            if len(split_para) > max_words_per_para:\n",
        "                chapters[i]['paras'].insert(j + 1, ' '.join(split_para[max_words_per_para:]))\n",
        "                chapters[i]['paras'][j] = ' '.join(split_para[:max_words_per_para])\n",
        "\n",
        "        chapters[i]['paras'] = [para.strip() for para in chapters[i]['paras'] if len(para.strip()) > 0]\n",
        "        if len(chapters[i]['title']) == 0:\n",
        "            chapters[i]['title'] = '(Unnamed) Chapter {no}'.format(no=i + 1)\n",
        "\n",
        "def print_previews(chapters):\n",
        "    for (i, chapter) in enumerate(chapters):\n",
        "        title = chapter['title']\n",
        "        wc = len(' '.join(chapter['paras']).split(' '))\n",
        "        paras = len(chapter['paras'])\n",
        "        initial = chapter['paras'][0][:20]\n",
        "        preview = '{}: {} | wc: {} | paras: {}\\n\"{}...\"\\n'.format(i, title, wc, paras, initial)\n",
        "        print(preview)\n",
        "\n",
        "def get_chapters(book_path, print_chapter_previews, first_chapter, last_chapter):\n",
        "    book = epub.read_epub(book_path)\n",
        "    parts = list(book.get_items_of_type(ebooklib.ITEM_DOCUMENT))\n",
        "    chapters = [part_to_chapter(part) for part in parts if part_to_chapter(part) is not None]\n",
        "    last_chapter = min(last_chapter, len(chapters) - 1)\n",
        "    chapters = chapters[first_chapter:last_chapter + 1]\n",
        "    format_paras(chapters)\n",
        "    if print_chapter_previews:\n",
        "        print_previews(chapters)\n",
        "    return chapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "G8Zk4dz4fR__",
        "outputId": "fd45d2a4-792b-4b28-9c1b-4e0fd034a532"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "doc_model = 'text-search-{model}-doc-001'.format(model=model)\n",
        "query_model = 'text-search-{model}-query-001'.format(model=model)\n",
        "\n",
        "def get_embedding(text, doc=True):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    model = doc_model if doc else query_model\n",
        "    response = openai.Embedding.create(input=[text], model=model)\n",
        "    return response['data'][0]['embedding']\n",
        "\n",
        "def get_embeddings(chapters):\n",
        "    embeddings = []\n",
        "    for chapter in chapters:\n",
        "        for para in chapter['paras']:\n",
        "            embeddings.append(get_embedding(para))\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7EL8YsTafSAA",
        "outputId": "9d5cf5bb-69ee-44b2-da50-a20ab48283ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def read_json(json_path):\n",
        "    print('Loading embeddings from \"{}\"'.format(json_path))\n",
        "    with open(json_path, 'r') as f:\n",
        "        values = json.load(f)\n",
        "    return (values['chapters'], np.array(values['embeddings']))\n",
        "\n",
        "def read_epub(book_path, json_path, preview_mode, first_chapter, last_chapter):\n",
        "    chapters = get_chapters(book_path, preview_mode, first_chapter, last_chapter)\n",
        "    if preview_mode:\n",
        "        return (chapters, None)\n",
        "    print('Generating {} embeddings for chapters {}-{} in \"{}\"\\n'.format(model, first_chapter, last_chapter, book_path))\n",
        "    embeddings = get_embeddings(chapters)\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump({'chapters': chapters, 'embeddings': embeddings}, f)\n",
        "    return (chapters, np.array(embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "f96bzbXL7jma",
        "outputId": "6be38158-dabc-41cd-d2fc-bd92f4b1e60a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embeddings from \"/content/embeddings-8-18-babbage-Charles C. Mann - The Wizard and the Prophet_ Two Remarkable Scientists and Their Dueling Visions to Shape Tomorrow’s World-Knopf Publishing Group (2018).epub.json\"\n"
          ]
        }
      ],
      "source": [
        "def process_file(path, preview_mode=False, first_chapter=0, last_chapter=math.inf):\n",
        "    values = None\n",
        "    if path[-4:] == 'json':\n",
        "        values = read_json(path)\n",
        "    elif path[-4:] == 'epub':\n",
        "        json_path = 'embeddings-{}-{}-{}-{}.json'.format(first_chapter, last_chapter, model, path)\n",
        "        if exists(json_path):\n",
        "            values = read_json(json_path)\n",
        "        else:\n",
        "            values = read_epub(path, json_path, preview_mode, first_chapter, last_chapter) \n",
        "    else:\n",
        "        print('Invalid file format. Either upload an epub or a json of book embeddings.')        \n",
        "    return values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comments below only relevant if you want to save yourself some API calls.\n",
        "\n",
        "# Run this with 'preview_mode' on if you want to figure out which chapters to include.\n",
        "# For example, after you run, 'process_file(path, preview_mode=True)',\n",
        "# you might notice that chapters 1-7 and 19-27 are useless endnotes/intro stuff.\n",
        "# So then you can run, 'process_file(path, first_chapter=8, last_chapter=18)'\n",
        "\n",
        "chapters, embeddings = process_file(path)"
      ],
      "metadata": {
        "id": "w9ZEETWkDxmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RwOITDD5fSAA",
        "outputId": "0a5cba0b-9bcd-4dc7-9a04-119b79d911a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def print_and_write(text, f):\n",
        "    print(text)\n",
        "    f.write(text + '\\n')\n",
        "\n",
        "def cos_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "def para_index_to_info(index, chapters):\n",
        "    for chapter in chapters:\n",
        "        paras_len = len(chapter['paras'])\n",
        "        if index < paras_len:\n",
        "            return chapter['paras'][index], chapter['title'], index\n",
        "        index -= paras_len\n",
        "    return None\n",
        "\n",
        "def search(query, embeddings, n=3):\n",
        "    query_embedding = np.array(get_embedding(query, doc=False))\n",
        "    results = sorted([i for i in range(len(embeddings))], key=lambda i: cos_similarity(embeddings[i], query_embedding), reverse=True)[:n]\n",
        "\n",
        "    f = open('result.text', 'a')\n",
        "    header_msg ='Results for query \"{}\" in \"The Wizard and the Prophet.epub\"'.format(query)\n",
        "    print_and_write(header_msg, f)\n",
        "    for result in results:\n",
        "        para, title, para_no = para_index_to_info(result, chapters)\n",
        "        result_msg = '\\nChapter: \"{}\", Passage number: {}, Score: {:.2f}\\n\"{}\"'.format(title, para_no, cos_similarity(embeddings[result], query_embedding), para)\n",
        "        print_and_write(result_msg, f)\n",
        "    print_and_write('\\n', f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "zCJx4wZ7fSAB",
        "outputId": "cdbb2480-cb02-453c-bfaf-81cac37f48de"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for query \"scene of vought and huxley meeting\" in \"The Wizard and the Prophet.epub\"\n",
            "\n",
            "Chapter: \"[ EIGHT ] The Prophet\", Passage number: 4, Score: 0.39\n",
            "\"Julian Huxley, 1964 Credit 77\n",
            "After the meeting Huxley and Vogt talked. Surely it was an exciting moment for Vogt. Speaking to Huxley, with his first-class Oxford degree, his links to scientists around the world, his string of best-selling books, was about as far from the Chincha Islands as it was possible to get. And Huxley had sought out Vogt, had questions for him, possible plans. No record exists of their conversation, though presumably Vogt talked about his forthcoming book, Road to Survival. Whatever the course of discussion, it is clear that Vogt satisfied Huxley. The two men kept in touch, sometimes by letter, sometimes through their mutual acquaintance, Vogt’s friendly rival Fairfield Osborn.\n",
            "During the next year Huxley watched Road become an explosive best seller, making Vogt—and Osborn, who had published a competing book—a prominent advocate for reducing human demands on the world’s ecosystems by reducing human numbers. Huxley and his brother Aldous believed with equal passion in the same cause, but had had much less success in gaining an audience. Meanwhile, Vogt was poised to become a statesman of ecology.\"\n",
            "\n",
            "Chapter: \"[ EIGHT ] The Prophet\", Passage number: 3, Score: 0.38\n",
            "\"Huxley was appalled. In his view, these ideas would license big corporations to use researchers’ discoveries to pillage what remained of the natural world. Like Truman, Huxley believed that scientific expertise could guide society into a more rational and prosperous form. But he thought it should do this by bringing nature and civilization into balance. Researchers could identify ecological limits, and teach governments how to live within them. Among the biggest obstacles to this biological reordering of the world, in Huxley’s view, were the blindly pro-growth policies of the U.S. government. From the officials in the Academy of Sciences boardroom, sympathetic despite their positions in the Truman administration, Huxley was seeking advice on how to create voices for nature in Washington. He wanted something in addition from Vogt: to know whether Vogt, from Huxley’s point of view a little-known but promising bureaucrat/ornithologist, was ready to step onto the world stage.\"\n",
            "\n",
            "Chapter: \"[ TEN ] The Edge of the Petri Dish\", Passage number: 10, Score: 0.38\n",
            "\"Wilberforce’s remark about Huxley’s ape ancestors was thus more than a snarky gibe. Consciously or not, the bishop was effectively asking whether Huxley was prepared to affirm that he and all other people were prisoners of biology. Blinded by contempt, Huxley seems not to have realized that his adversary was posing, however rudely, an important question. (The “great question,” the great conservationist George Perkins Marsh called it a few years later: “whether man is of nature or above her.”) Not grasping the underpinnings of the dispute, Huxley didn’t even try to engage them. Darwin later shuddered at the “awful battles which have raged about ‘species’ at Oxford,” but there was no actual debate. At least not in the sense of a genuine attempt to hash out diverging beliefs.\n",
            "Both Huxley and Wilberforce thought they had come off well. Three days after the encounter, the bishop bragged to a friend, “I think I thoroughly beat him.” Certainly his supporters in the audience, “cheering lustily,” thought so. Equally pleased, Huxley later boasted that he “was the most popular man in Oxford for full four and twenty hours afterwards.” In the years to come, Huxley and Wilberforce ran into each other from time to time. The meetings were always cordial. Both viewing themselves as the winner, they could be magnanimous in victory.\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = 'scene of vought and huxley meeting' #@param {type:\"string\"}\n",
        "search(query, embeddings)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('ai')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "081fcd66225760048f81a201a796f3f29a20e0e4c35b433e7d0deae44a19c67d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}